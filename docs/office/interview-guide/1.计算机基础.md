---
title: 基础题库
sidebar_label: 基础题库
slug: base-computer
description: 基础题库
---

### OSI七层协议
OSI七层协议是一种网络通信协议。它定义了我们计算机网络结构基础。

1. 物理层（Physical Layer）：
   - 在物理层，数据被转换成电信号或光信号，并通过物理媒体（如电缆、光纤或无线信号）传输到网络。

2. 数据链路层（Data Link Layer）：
   - 在数据链路层，数据帧被创建，其中包含源和目标MAC地址，以便在局域网络中传输。

3. 网络层（Network Layer）：
   - 在网络层，数据包被创建，其中包含源和目标IP地址。路由器位于这一层，并使用目标IP地址来决定如何将数据包从源服务器发送到目标服务器。
   - 源服务器将数据包发送到本地路由器，然后通过多个中继路由器和WAN连接的网络传输到目标城市的路由器。

4. 传输层（Transport Layer）：
   - 在传输层，数据包被分割成较小的数据段，并添加源和目标端口号。这一层确保数据的可靠传输，并提供错误检测和纠正功能。
   - 数据包经过多次路由和转发，直到它们达到目标城市的路由器。

5. 会话层（Session Layer）：
   - 会话层负责建立、管理和终止通信会话。它确保数据包以正确的顺序到达目标服务器，并处理任何通信会话的控制和同步。

6. 表示层（Presentation Layer）：
   - 表示层负责数据的格式转换和加密解密等安全性和数据格式问题。在这里，数据可能会被加密，以保护其隐私和完整性。

7. 应用层（Application Layer）：
   - 在应用层，最终的应用程序处理请求。这可能包括Web服务器、数据库服务器或其他应用程序服务器，根据请求的类型执行相应的操作。

---

### 三次握手和四次挥手
三次握手和四次挥手是TCP连接中的一种确保连接建立的可靠性机制，也就是它能够确保连接被正确的建立。

#### 三次握手（建立连接）

1. **第一步**：客户端发送一个SYN信号请求到服务器，表示请求建立连接。

2. **第二步**：服务器接收到客户端的SYN数据包后，回应一个带有SYN和ACK信号响应，表示接收连接请求并准备好建立连接。

3. **第三步**：客户端接收到服务器的SYN和ACK数据包后，向服务器发送一个带有ACK标志的数据包，表示连接建立成功。此时，客户端和服务器之间的连接已建立，可以开始进行数据传输。

TCP连接是一种可靠连接，他需要确保服务双方至少完成一次通信。我们可以从反向推到为什么是三次握手：
- 假设一次握手：客户端发送SYN信号数据，此时客户端认为连接已经成功建立，开始发送请求。但实际建立连接的请求可能再网络中滞留，所以会对服务端造成困扰。
- 假设两次握手：客户端发送SYN信号数据，服务端响应SYN&ACK信号数据，此时表示连接已经成功建立。但同样，此时对于客户端来说，只要建立连接的请求发送出去，就表示连接已经建立。

因此，至少需要三次握手，才能确保客户端和服务端至少都有过一次交互，这样可以大大减少异常。

#### 四次挥手（终止连接）

1. **第一步**：客户端发送一个带有FIN信号请求到服务器，表示请求关闭连接，但仍愿意接收数据。

2. **第二步**：服务器接收到客户端的FIN数据包后，回应一个带有ACK标志的数据包，表示已收到关闭请求。

3. **第三步**：服务器完成了未完成的数据传输后，发送一个带有FIN标志的数据包到客户端，表示已准备好关闭连接。

4. **第四步**：客户端接收到服务器的FIN数据包后，回应一个带有ACK标志的数据包，表示已收到关闭请求。此时，连接被完全终止。

TCP连接是一种可靠连接，他需要确保服务双方至少完成一次通信。断连需要确保服务双方资源正确释放。我们仍然反向推导为什么是四次挥手：
- 假设一次挥手：客户端发送FIN信号请求，表示客户端连接已经断开了。但服务端可能没有收到断连的请求，从而导致服务端资源被占用。
- 假设两次挥手：同样客户端发送一次断连请求之后认为连接已经断开。
- 假设三次挥手：可能导致客户端无法释放资源。

---

### 什么是C/S架构和B/S架构
C/S架构和B/S架构是两种常见的计算机软件架构模型。

1. C/S架构（Client/Server架构）：客户端通常是桌面应用程序或移动应用程序。服务端通常则提供接口服务。

2. B/S架构（Browser/Server架构）：其中客户端是Web浏览器。

---

### ARP
ARP（地址解析协议，Address Resolution Protocol）协议的主要用途是在局域网络内建立和维护IP地址和MAC地址之间的映射关系。

---

### CDN

CDN代表**内容分发网络**（Content Delivery Network）。它是一种**分布式网络架构**，常用于静态资源的加速。

如果要刷新CND缓存，可以通过添加一些时间戳参数等。

### DNS

DNS表示域名系统，用于将域名转化为对应的IP地址，DNS的目标是提供域名和IP之间的映射。

---

### CORS
CORS是浏览器的一种安全策略，它限制浏览器跨域http请求。在前后端联调中是比较常见的，处理方式就是通过追加 Access-Control-Allow-Origin 响应头字段，用于管理浏览器跨域行为。

1. CORS（跨源资源共享）：
   - 目的：CORS是一种用于控制在Web浏览器中的跨域请求的机制。它的主要目的是允许Web页面从一个域（或来源）请求另一个域的资源，例如从一个域的JavaScript代码向另一个域请求数据或资源。这是为了安全原因而限制的，以防止恶意网站滥用客户端的能力来访问其他域的资源。
   - 工作原理：当一个浏览器发送跨域请求时，目标服务器可以配置CORS策略来指定哪些域可以访问其资源。浏览器会发送一个预检请求（OPTIONS请求）以确定是否允许跨域请求，并根据服务器的响应来决定是否允许跨域请求。如果服务器返回适当的CORS头（例如Access-Control-Allow-Origin），则浏览器允许跨域请求。


### CORS和CSRF
CORS是浏览器的一种安全策略，而CSRF是一种网络攻击，其目的是伪造用户的请求以执行未经授权的操作，站点需要采取措施来防范CSRF攻击。

1. CORS（跨源资源共享）：
    - 目的：CORS是一种用于控制在Web浏览器中的跨域请求的机制。它的主要目的是允许Web页面从一个域（或来源）请求另一个域的资源，例如从一个域的JavaScript代码向另一个域请求数据或资源。这是为了安全原因而限制的，以防止恶意网站滥用客户端的能力来访问其他域的资源。
    - 工作原理：当一个浏览器发送跨域请求时，目标服务器可以配置CORS策略来指定哪些域可以访问其资源。浏览器会发送一个预检请求（OPTIONS请求）以确定是否允许跨域请求，并根据服务器的响应来决定是否允许跨域请求。如果服务器返回适当的CORS头（例如Access-Control-Allow-Origin），则浏览器允许跨域请求。

2. CSRF（跨站点请求伪造）：
    - 目的：CSRF是一种攻击，其目的是利用用户在另一个站点已经经过身份验证的情况下，伪造用户的请求以执行未经授权的操作。攻击者试图利用用户的身份来执行某些操作，而用户可能不知情。
    - 工作原理：攻击者会伪造包含恶意操作的请求，并将它们发送到目标站点，而用户可能已经在目标站点登录。如果目标站点没有适当的防护措施，它可能会执行这些操作，以用户的身份进行操作。为了防范CSRF攻击，站点通常使用CSRF令牌（也称为同步令牌）来验证请求的合法性。CSRF令牌是一个随机生成的令牌，它必须与请求一起发送，并且与用户的会话相关联。如果请求不包含有效的CSRF令牌，服务器将拒绝执行请求。

简单来讲，CORS是一种浏览器安全策略，它限制浏览器跨域http请求。
CSRF是一种网络安全攻击手段，它通过用过用户在应用程序中已经认证过的信息，模拟用户行为执行一些非法的行为。

---

### 系统调度算法
当谈到 CPU 调度算法时，有几种经典的算法以及它们的工作原理，包括：

1. **先来先服务 (First-Come, First-Served, FCFS)**：
   - 原理：进程按照它们进入就绪队列的顺序依次执行。即，第一个进入队列的进程首先执行，直到它完成或被阻塞。
   - 优点：简单，易于理解。
   - 缺点：可能导致短作业等待长作业（"饥饿"问题），效率低下。

2. **轮转调度 (Round Robin, RR)**：
   - 原理：每个进程被分配一个时间片，当时间片用尽时，它被放回队列的末尾，然后下一个进程执行。这个过程循环重复。
   - 优点：公平，适用于时间片轻微不同的进程。
   - 缺点：可能导致上下文切换开销，不适合长时间运行的进程。

3. **完全公平调度**(Completely Fair Scheduler，CFS)：
   - 原理：CFS 的目标是实现公平的 CPU 时间分配，以确保所有就绪状态的进程在一定时间内都能获得相等的 CPU 时间份额，而不考虑它们的优先级。它使用虚拟运行时间（virtual runtime）的概念来确定下一个执行的进程。
   - 工作方式：CFS 维护一个红黑树数据结构，进程按照它们的虚拟运行时间在树中排列。具有最小虚拟运行时间的进程被认为是下一个执行的进程。每个进程的虚拟运行时间会根据实际执行时间进行动态调整，以确保公平性。
   - 优点：提供了相对公平的 CPU 时间分配，适用于多任务系统，不会让长时间运行的进程占用过多资源。进程在运行时会累积虚拟运行时间，进程的优先级取决于它的虚拟运行时间，执行时间越短，优先级越高。
   - 缺点：可能会引入一些上下文切换开销，因为调度器需要频繁检查和更新虚拟运行时间。

---

### 自旋锁和阻塞锁
自旋锁和阻塞锁本质都是互斥锁。它用于并发编程模型中对共享资源的访问。它们适用场景有一定的不同。

假设某一个共享资源已经被某个线程占据时。这时我们使用不同的锁会发生不同的场景。
当我们使用阻塞锁时，当前线程会进行休眠等待系统调度。
当我们使用自旋锁时，当前线程会不间断去探测锁是否可用，线程是不会直接进入休眠的。

因此，对一些耗时很短的执行操作（比如内存操作等），我们可以使用自旋锁，这样可以避免系统频繁的调度开销。
对于一些耗时比较长的执行操作（比如网络IO、文件IO等），我们可以使用阻塞锁，这样就可以减少资源开销。

```python title="自旋锁"
import threading

class SpinLock:
    def __init__(self):
        self.lock = threading.Lock()

    def acquire(self):
        while not self.lock.acquire(blocking=False):
            pass

    def release(self):
        self.lock.release()

# 使用自旋锁
spin_lock = SpinLock()

def example_function():
    spin_lock.acquire()
    # 临界区代码
    spin_lock.release()

# 启动多个线程
threads = []
for _ in range(5):
    thread = threading.Thread(target=example_function)
    threads.append(thread)
    thread.start()

for thread in threads:
    thread.join()
```

### 互斥锁正常模式和饥饿模式
正常模式和饥饿模式是锁的两种不同的分配策略。在并发编程模型中，不同的策略会影响获取锁的优先级和公平性。  
正常模式下，锁的分配是相对公平的，所有等待锁的线程都有机会去获取锁。  
而在饥饿模式下，锁的分配会更偏向于高优先级的线程，而低优先级的可能会长时间无法获得锁，导致它们饥饿。  


### 自旋锁占用资源如何解决
可以基于不同的场景适当考虑锁的使用。当锁竞争激烈的时候，可以考虑使用阻塞锁。避免自旋锁导致的性能问题。
或者在自旋锁的基础上引入一定的机制，长时间无法获取锁的时候可以逐渐增加等待时间。

### CAS 具体是怎么实现的呢？
CAS（Compare-And-Swap）是一种并发编程中常用的原子操作，通常用于实现无锁数据结构，以解决多线程并发访问的竞态条件问题。CAS操作在硬件层面上可以是原子的，但在高级编程语言中，CAS通常是通过特殊的指令来实现的。

具体来说，CAS操作包含三个参数：

1. **内存地址（地址A）：** 指向要被修改的共享变量的内存地址。
2. **旧值（旧值B）：** 期望的当前变量值。
3. **新值（新值C）：** 指定要写入的新值。

CAS操作的原理是，仅当地址A上的当前值等于旧值B时，才将地址A上的值更新为新值C。整个操作是原子的，即在操作期间不会被其他线程干扰。如果地址A上的当前值不等于旧值B，说明在操作过程中共享变量已经被其他线程修改过，此时CAS操作会失败，不会执行写入新值C的操作，而是返回失败。

在多线程环境中，通过CAS可以实现一些基本的同步原语，例如实现无锁的计数器、队列等数据结构。在底层硬件层面上，通常有专门的指令来支持CAS操作，例如`cmpxchg`（x86架构）或`ldrex/strex`（ARM架构）。

在高级编程语言中，CAS通常由编程语言提供的原子操作库或底层系统支持实现。例如，在Go语言中，`sync/atomic`包提供了`CompareAndSwap`等原子操作函数，可以用于实现CAS。以下是Go语言中的一个简单示例：

```go
package main

import (
	"fmt"
	"sync/atomic"
)

func main() {
	var value int32 = 42

	// 使用CAS操作将value从旧值42更新为新值100
	success := atomic.CompareAndSwapInt32(&value, 42, 100)

	fmt.Println("CAS operation successful?", success)
	fmt.Println("New value:", value)
}
```

这个示例中，如果`value`的当前值是42，那么CAS操作将把它更新为新值100，并返回`true`表示操作成功。否则返回`false`。

### int类型占几个字节
int类型通常占据4各字节或者8各字节，具体取决于操作系统类型。

如果是32位操作系统，int类型的大小就是4字节。

如果是64位操作系统，int类型的大小就是8个字节。

### 一致性哈希
一致性哈希是一种解决分布式系统中数据分片和负载均衡的方法。其核心思想是将节点和数据都映射到同一个哈希环上，通过哈希算法将节点和数据散列到环上的某个位置。这样，当有新的节点加入系统或者节点失效时，只需重新映射和移动少量的数据，而不需要重新分配整个数据集。

一致性哈希的主要特点包括：

1. **节点和数据映射：** 通过哈希算法，将节点和数据映射到同一个环上，通常是一个圆环。
2. **均衡性：** 由于节点和数据在哈希环上均匀分布，可以达到负载均衡的效果。
3. **容错性：** 当节点加入或离开系统时，只需重新映射和移动少量的数据，不需要重新分配整个数据集，从而提高了系统的容错性。
4. **扩展性：** 当需要扩展系统的容量时，可以方便地添加新的节点，而不会对现有的节点和数据产生大量影响。
5. **简单性：** 一致性哈希的实现相对简单，易于理解和部署。

在一致性哈希中，哈希环上的每个点都对应一个节点或数据的位置，而哈希值决定了节点或数据在环上的位置。当需要查找数据时，通过哈希算法计算数据的哈希值，找到哈希环上最近的节点，从而确定数据所在的节点。

### select 和 epoll 的区别
`select` 和 `epoll` 都是用于处理I/O多路复用的机制，但它们有一些关键的区别。

#### `select`:

1. **限制连接数量：** `select` 的工作方式是通过遍历文件描述符集合，因此它对文件描述符的数量有一定的限制。通常，它能够支持的最大文件描述符数量在系统中是有限制的，可能会受到性能的影响。

2. **复制开销：** 在每次调用 `select` 时，都需要将文件描述符的集合从用户空间复制到内核空间，这会带来一定的开销，特别是在文件描述符数量很大时。

3. **不支持水平触发：** `select` 对于就绪状态的通知是通过轮询实现的，这被称为边缘触发（edge-triggered）模式。这意味着如果一个文件描述符就绪了但没有读取完数据，下次 `select` 调用时仍然会通知。

#### `epoll`:

1. **没有文件描述符数量限制：** `epoll` 使用一组文件描述符来管理事件，因此它没有 `select` 中的文件描述符数量限制。这使得 `epoll` 在处理大量连接时更为高效。

2. **零拷贝：** `epoll` 提供了零拷贝特性，它可以在内核空间和用户空间之间传递数据的指针，而不需要中间的数据拷贝，提高了性能。

3. **支持水平触发：** `epoll` 可以以水平触发（level-triggered）模式工作，这意味着只要文件描述符处于就绪状态，每次等待都会被通知，不仅仅是在状态改变时。

4. **提供更灵活的事件管理：** `epoll` 提供了更灵活的事件管理机制，允许监听多种事件类型，而不仅仅是读和写。

总体而言，`epoll` 在处理大量连接和高并发的情况下性能更好，并且提供了更灵活的事件管理。在现代的Linux系统中，`epoll` 更常用于实现高性能的网络服务。

### 乐观锁和悲观锁
乐观锁和悲观锁是两种处理并发访问时的不同策略，用于确保数据的一致性和完整性。

#### 1. 乐观锁（Optimistic Locking）：

在乐观锁中，系统假定在大多数情况下，数据不会发生冲突，因此允许多个事务同时访问和修改相同的数据。冲突的检测和解决是在提交事务时进行的。

常见的乐观锁实现方式是使用版本号或时间戳。每次读取数据时，都会获取数据的版本号或时间戳。在提交更新时，检查数据的版本号或时间戳是否仍然是读取时的值。如果是，则说明没有其他事务修改过这条数据，可以提交更新；如果不是，则可能发生了冲突，需要进行冲突解决。

乐观锁的优势在于不需要显式的锁定资源，适用于读多写少的场景，减少了锁竞争，提高了系统的并发性能。

#### 2. 悲观锁（Pessimistic Locking）：

悲观锁的策略是在事务访问数据时，认为其他事务可能同时访问相同的数据，因此在事务访问时将数据锁定，确保其他事务无法同时修改该数据。

常见的悲观锁实现方式包括共享锁和排它锁。共享锁允许多个事务同时读取同一数据，但阻止其他事务获得排它锁；排它锁则阻止其他事务同时读取和修改数据。

悲观锁的优势在于确保数据的一致性，但劣势在于可能引起性能问题，尤其是在高并发的场景下，因为它要求对共享资源进行显式的锁定和解锁，可能导致锁竞争和阻塞。

#### 选择锁的考虑因素：

- **并发性需求：** 如果系统对并发性能要求较高，乐观锁可能更适合，因为它允许更多的并发访问。

- **事务的持续时间：** 如果事务需要锁定数据的时间较长，悲观锁可能更合适，因为乐观锁需要在提交时检查冲突，可能导致事务更长时间的持有锁。

- **冲突频率：** 如果冲突频率较低，乐观锁的开销可能较小；如果冲突频率较高，悲观锁可能更能保证数据的一致性。

- **实现复杂性：** 乐观锁的实现相对简单，通常通过版本号或时间戳即可，而悲观锁的实现可能需要更多的考虑，例如锁的粒度和释放时机。

### 加锁的话一般有哪些类型呢？
在并发编程中，加锁是为了保护共享资源，防止多个线程同时修改数据而导致不一致或不可预测的结果。常见的锁类型包括：互斥锁、读写锁、自旋锁、原子锁等

### 1. 互斥锁（Mutex Lock）：

- **概念：** 互斥锁是一种最基本的锁，它保证同一时刻只有一个线程可以访问共享资源。

- **特点：** 当一个线程获取了互斥锁，其他线程必须等待该线程释放锁才能继续执行。

### 2. 读写锁（Read-Write Lock）：

- **概念：** 读写锁分为读锁和写锁，多个线程可以同时持有读锁，但只有一个线程可以持有写锁。

- **特点：** 读锁用于读取共享资源，写锁用于修改共享资源。多个线程可以同时持有读锁，但写锁是独占的。

### 3. 信号量（Semaphore）：

- **概念：** 信号量是一个计数器，表示同时允许多少个线程进入临界区。信号量可以用于控制并发线程的数量。

- **特点：** P（等待）和 V（释放）是信号量的两个基本操作。P 减小计数器，V 增加计数器。当计数器大于零时，允许进入临界区。

### 4. 条件变量（Condition Variable）：

- **概念：** 条件变量用于线程间的通信，允许一个线程等待某个条件成立，而另一个线程在满足条件时通知等待的线程。

- **特点：** 通常和互斥锁一起使用，等待时释放互斥锁，被通知时重新获取互斥锁。

### 5. 自旋锁（Spin Lock）：

- **概念：** 自旋锁是一种忙等待锁，线程在获取锁失败时不会阻塞，而是反复尝试获取锁。

- **特点：** 适用于短期占用，等待时间较短的情况，避免了线程切换的开销。但长时间自旋会浪费 CPU 资源。

### 6. 递归锁（Recursive Lock）：

- **概念：** 递归锁允许同一线程多次获得同一把锁，而不会发生死锁。

- **特点：** 每次加锁都要相应的解锁，只有当最后一次解锁时，其他线程才能获得这个锁。

### 7. 读-写自旋锁（Read-Write Spin Lock）：

- **概念：** 类似于读写锁，但是使用忙等待的方式。

- **特点：** 适用于读操作远远多于写操作的场景，减少了读写锁在低争用场景下的性能开销。

### 8. CAS（Compare-And-Swap）：

- **概念：** CAS 是一种无锁原子操作，通常用于实现自旋锁。它比传统的锁机制更轻量，但可能存在 ABA 问题。

- **特点：** CAS 操作会比较变量的当前值与期望值，如果相等，则更新为新值。CAS 操作是原子性的。

