---
title: k8s
---

在了解 k8s 前，我们需要先了解下 **服务部署** 的演进，主要包括：
* 传统部署
* 虚拟化部署
* 容器化部署

## 传统部署
传统部署即直接将应用程序部署在服务器上，通过类似 `nohup` 的方式运行在后台。

这种部署方式整体来看是比较简单的，但是存在一个致命的问题：  
服务器部署多应用时，无法定义**应用程序资源使用边界**。

简单点说就是应用程序之间存在资源冲突，包括到端口，CPU、内存等资源的冲突。

:::note 线上资源冲突案例
服务器上部署了多个应用程序，高峰时期，某个应用程序会跑满CPU、内存，导致其他应用直接 Crash 无法恢复。  

最后复盘结论就是服务器资源不足，申请加了服务器。  
将应用分别部署了一份，解决了高峰期的问题。  
但在低峰期，服务器基本空置。
:::

## 虚拟化部署
虚拟化技术通常指我们使用的虚拟机。虚拟机拥有隔离的操作系统、计算、内存、存储等资源，是一个独立的环境。

虚拟化部署，即通过在一台服务器上运行多个虚拟机，然后将应用分别部署在虚拟机中。

相对于传统部署的方式来说，它保证了应用部署环境的纯净性，但相对的，单独运行一个虚拟机，也是十分耗费资源的。

## 容器化部署
大部分容器技术，底层都是基于 Linux Namespace 和 CGroups 实现。  
虽然容器技术很早就有（Docker 底层 `runc` 就基于 Namespace 实现），但大多数都存在后期运维不便的问题，所以并不流行。  
直到 Docker 的出现，彻底掀起容器技术的热潮。

Docker 引入了镜像的概念，大大的简化容器的创建、销毁、部署的问题。

相对于虚拟化部署的方式来说，它共享当前操作系统，在此之上，通过  Container Runtime 创建轻量级的容器。

:::note Container Runtime 容器运行时
以 Docker 为例，创建并运行一个容器，包含两个运行时： `high-level container runtime` 和 `low-level container runtime`。

`high-level container runtime` 负责镜像管理、api、gRPC 接口管理等。  
`low-level container runtime` 则负责具体运行的容器。  
:::

## k8s 简介
Kubernetes 简称 k8s，它本质是一个分布式的集群系统，采用主从架构，分别称之为控制节点和工作节点。

我们在上面说到，容器化部署，解决了资源隔离、利用的问题，但是运维期间仍然不可避免的存在其他问题，主要包括：
1、容器

k8s 是一个基于容器技术的分布式服务器集群，集群采用的是一个master多个worker，一个控制节点和多个工作节点，特点就是，提供优秀的容器编排能力。
容器编排：
容器扩缩容
容器自愈
服务发现
负载均衡


master节点：
ApiServer：操作集群资源对象的唯一入口，提供用户认证，授权，api注册和发现的功能
Scheduler：负责集群资源调度，按照预定的调度策略，将Pod调度到对应的节点上
ControllerManager：负责维护集群状态，Pod部署、自愈、扩缩容
Etcd：存储集群中所有的资源对象信息

work节点：
kubelet：负责维护容器的生命周期
kubeProxy：负责集群内的负载均衡和服务发现
CRI

一个简答的问题，用户调用kubectl指令部署一个Pod，中间会执行那些流程：
首先指令会走到apiServer服务，进行用户认证以及权限认证
然后会调用Schedule组件，根据用户指定的调度策略来确定具体的调度节点
然后通过ControllerManager组件通知对应的节点
节点上的kubelet组件接收ControllerManager组件的事件，创建对应的Controller，管理Pod的生命周期
外部流程则通过kubeproxy访问Pod
