---
title: k8s
---

在了解 k8s 前，我们需要先了解下 **服务部署** 的演进，主要包括：
* 传统部署
* 虚拟化部署
* 容器化部署

## 传统部署
传统部署即直接将应用程序部署在服务器上，通过类似 `nohup` 的方式运行在后台。

这种部署方式整体来看是比较简单的，但是存在一个致命的问题：  
服务器部署多应用时，无法定义**应用程序资源使用边界**。

简单点说就是应用程序之间存在资源冲突，包括到端口，CPU、内存等资源的冲突。

:::note 线上资源冲突案例
服务器上部署了多个应用程序，高峰时期，某个应用程序会跑满CPU、内存，导致其他应用直接 Crash 无法恢复。  

最后复盘结论就是服务器资源不足，申请加了服务器。  
将应用分别部署了一份，解决了高峰期的问题。  
但在低峰期，服务器基本空置。
:::

## 虚拟化部署
虚拟化技术通常指我们使用的虚拟机。虚拟机拥有隔离的操作系统、计算、内存、存储等资源，是一个独立的环境。

虚拟化部署，即通过在一台服务器上运行多个虚拟机，然后将应用分别部署在虚拟机中。

相对于传统部署的方式来说，它保证了应用部署环境的纯净性，但相对的，单独运行一个虚拟机，也是十分耗费资源的。

:::note
随着虚拟化的流行，出现了 OpenStack、VMWare 之类的虚拟化管理系统，为云原生服务奠定了基础。
:::

## 容器化部署
主流容器技术，底层都是基于 Linux Namespace 和 CGroups 实现。  
虽然容器技术很早就存在了，但它们大多数都存在后期运维不便的问题，所以并不流行。  
直到 Docker 的出现，彻底掀起容器技术的热潮。

Docker 引入了镜像的概念，并且定义了镜像构建、发布和运行的标准。

开发人员可以快速的对应用进行镜像构建，然后发布镜像，最后在生产环境中创建容器运行，这极大的简化应用的生产流程。

相对于虚拟化部署的方式来说，它更节省资源，因为容器共享当前操作系统。
在此基础之上，通过  Container Runtime 定义资源界限，从而创建轻量级的容器环境。

:::note Container Runtime 容器运行时
以 Docker 为例，创建并运行一个容器，包含两个运行时： `high-level container runtime` 和 `low-level container runtime`。

`high-level container runtime` 负责镜像管理、api、gRPC 接口管理等。  
`low-level container runtime` 则负责具体运行的容器。  
:::

## k8s 简介
k8s 全称 Kubernetes，是一个容器调度管理系统，提供了完善的容器编排解决方案。

k8s 同时也是一个分布式的集群系统，由控制节点（master）、工作节点（node）、分布式存储（etcd）组成。  



控制节点包括：
APIServer  
Scheduler  
ControllerManager

工作节点包含：
Kubelet
ContainerRuntime
KubeProxy


k8s 同时也是一个容器调度管理系统，提供了基于容器技术的容器编排解决方案。

什么是容器编排？为什么需要容器编排？

我们在上面的容器化部署中已经介绍了容器化的优点，但是纵观整个应用的生命周期，它仍然存在一些问题：
当某个应用容器存在性能贫瘠时，希望对它进行简单的横向拓展，来提高服务能力。这个时候，我们可以通过再次部署一个容器来实现。
但是客户端时无法感知到新部署的容器的，所以需要提供服务发现和负载均衡机制，来确保我们的横向扩展。

这些问题都围绕着容器进行，我们针对容器的扩缩容、服务发现、负载均衡等称之为容器编排。
提供容器编排方案的服务有很多，我们选择 k8s。


## k8s 组成
控制节点：
APiServer
Scheduler
ControllerManager
Etcd

工作节点：
Kubelet
KubeProxy

## kubectl 执行过程
一条创建 Pod 的指令的工作流程：
首先通过 ApiServer，进行用户和权限验证
调用 Scheduler 组件，根据用户指定的调度策略来确定具体的调度节点
通过 ControllerManager 组件调用节点的 Kubelet，创建对应的 Controller，管理 Pod 的生命周期

一个外部的请求访问 Pod 的流程：
首先通过 Ingress
再走到 Service
再走到 Pod

## 开放接口 - CRI
CRI 全称 Container Runtime Interface，它定义了容器和镜像的服务接口规范。

在 k8s 中 node 节点会启动 CRI gRPC Server，该服务包含 RuntimeService 和 ImageService，其中：  
* RuntimeService 负责容器运行时管理  
* ImageService 负责镜像管理

Kubelet 则作为 gRPC Client 与 CRI gRPC Server 交互。

## 开放接口 - CNI

## 开放接口 - CSI


<!--

我们在上面说到，容器化部署，解决了资源隔离、利用的问题，但是运维期间仍然不可避免的存在其他问题，主要包括：
1、容器

k8s 是一个基于容器技术的分布式服务器集群，集群采用的是一个master多个worker，一个控制节点和多个工作节点，特点就是，提供优秀的容器编排能力。
容器编排：
容器扩缩容
容器自愈
服务发现
负载均衡


master节点：
ApiServer：操作集群资源对象的唯一入口，提供用户认证，授权，api注册和发现的功能
Scheduler：负责集群资源调度，按照预定的调度策略，将Pod调度到对应的节点上
ControllerManager：负责维护集群状态，Pod部署、自愈、扩缩容
Etcd：存储集群中所有的资源对象信息

work节点：
kubelet：负责维护容器的生命周期
kubeProxy：负责集群内的负载均衡和服务发现
CRI

一个简答的问题，用户调用kubectl指令部署一个Pod，中间会执行那些流程：
首先指令会走到apiServer服务，进行用户认证以及权限认证
然后会调用Schedule组件，根据用户指定的调度策略来确定具体的调度节点
然后通过ControllerManager组件通知对应的节点
节点上的kubelet组件接收ControllerManager组件的事件，创建对应的Controller，管理Pod的生命周期
外部流程则通过kubeproxy访问Pod

-->
