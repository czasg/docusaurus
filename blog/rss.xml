<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Czasg Blog</title>
        <link>https://czasg.github.io/docusaurus/blog</link>
        <description>Czasg Blog</description>
        <lastBuildDate>Tue, 01 Mar 2022 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <item>
            <title><![CDATA[数据库常用操作]]></title>
            <link>https://czasg.github.io/docusaurus/blog/2022/3/1/数据库常用操作</link>
            <guid>数据库常用操作</guid>
            <pubDate>Tue, 01 Mar 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[记录一些在工作常用的数据库操作]]></description>
            <content:encoded><![CDATA[<p>记录一些在工作常用的数据库操作</p><h2>mysql</h2><h2>postgres</h2><pre><code class="language-shell" metastring="script">psql -U postgres -d postgres
select * from pg_database;
select pg_database_size(&#x27;postgres&#x27;);
</code></pre><h2>redis</h2><pre><code class="language-shell" metastring="script title=&quot;连接 rds 并简单查询&quot;" title="&quot;连接">redis-cli
ping
auth password
select db
keys *
type key
</code></pre><br/><p>:::info 👇👇👇
<strong>本文作者:</strong> Czasg
<strong>版权声明:</strong> 转载请注明出处哦~👮‍
:::</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[数据库是否适合容器化部署]]></title>
            <link>https://czasg.github.io/docusaurus/blog/2022/2/22/数据库是否适合容器化部署</link>
            <guid>数据库是否适合容器化部署</guid>
            <pubDate>Tue, 22 Feb 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[随着 Kubernetes 的流行，越来越来的应用被打包成镜像，作为容器部署在 k8s 上。]]></description>
            <content:encoded><![CDATA[<p>随着 Kubernetes 的流行，越来越来的应用被打包成镜像，作为容器部署在 k8s 上。</p><p>在 k8s 中，pod 是最小的部署单位，内部可以包含多个容器镜像，每一个 pod 都具有有限的生命周期。<br/>
<!-- -->对于无状态服务来说，特别适合在 k8s 上运行，因为无状态服务，是具有弹性的，可以更好的应对 pod 扩缩容、重启等特性。<br/>
<!-- -->相反，对于有状态服务（类似数据库等），则存在一定的瓶颈限制。</p><p>先来看下 k8s 如何部署有状态服务，然后讨论下其优缺点。</p><h2>DaemonSet &amp; StatefulSet</h2><p><strong>DaemonSet</strong> 是 k8s 的控制器资源对象之一，其特点是：   </p><blockquote><p>1、确保每个节点仅启动一个 pod 副本，当有新节点加入集群时，自动为其增加一个 pod。</p></blockquote><p>比较典型的是日志收集服务，比如：我们需要确保每个节点上起一个 <code>logstash</code>，以便回收节点上的服务日志。  </p><p>数据库服务可以在类似场景下使用，比如给某个节点打上标签，确保某个数据库在对应节点上以 DaemonSet 类型启动，这样就可以确保该节点仅有一个 pod 副本。
最后通过 <code>nodeport</code> 的方式对外提供服务。
此时我们的数据库就拥有了稳定的节点 ip 和本地存储。  </p><p>但是这种方式，和直接在物理机上部署的方式差别不大，主要是复用了 k8s 的管理能力。</p><p><strong>StatefulSet</strong> 是 k8s 专为有状态服务设计的资源类型，它拥有：  </p><blockquote><p>1、稳定的网络标识：当服务重启，pod 绑定的 ip 不会变化，但是手动删除或者重建副本时，会重新分配 ip。
创建 headless service 时可以通过 <code>${serviceName-number}.${service}.${namespace}</code> 访问指定 pod。<br/>
<!-- -->2、稳定的持久存储：基于 pvc 实现，每个 pod 会绑定专有的 pvc 存储。<br/>
<!-- -->3、有序的扩缩容：会安装顺序从 0 逐一启动或者重建，此时类似滚动更新的扩容策略不在适用。      </p></blockquote><p>当我们的数据库服务部署 k8s 上时，可以选择 StatefulSet 资源类型。<br/>
<!-- -->它的基本特点，足够支持一个有状态服务的正常运转。</p><h2>性能瓶颈</h2><p>数据库主要是和存储打交道，其性能瓶颈通常在磁盘IO。<br/>
<!-- -->那么快速的磁盘IO，将有助于提升数据库的性能和吞吐量。<br/>
<!-- -->比如：分别部署在 HDD 和 SSD 上的两个数据库，在相同其他条件下，SSD 上的数据库肯定拥有更高的性能。 </p><p>当我们的数据库部署在 k8s 上时，可以通过挂载卷 volume（nfs、ceph）持久化数据，但是这样就不可避免的引入了网络IO，在本身就拉跨的瓶颈上又补一刀。<br/>
<!-- -->所以当我们使用 k8s 部署数据库时，可能需要重点考虑下性能问题。</p><p>除了 nfs、ceph 之外，还有 hostpath 这类本地存储，可以忽略网络影响。
但是这需要我们的副本绑定到固定的节点上，此时就走的类似 DaemonSet 的部署路线了。</p><br/><p>:::info 👇👇👇
<strong>本文作者:</strong> Czasg<br/>
<strong>版权声明:</strong> 转载请注明出处哦~👮‍
:::</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[golang升级导致goland不可用]]></title>
            <link>https://czasg.github.io/docusaurus/blog/2022/2/17/golang升级导致goland不可用</link>
            <guid>golang升级导致goland不可用</guid>
            <pubDate>Thu, 17 Feb 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[go1.14.1 升级至 go1.17.7，导致 goland 打开后显示无法找到 GOROOT。]]></description>
            <content:encoded><![CDATA[<p>go1.14.1 升级至 go1.17.7，导致 goland 打开后显示无法找到 GOROOT。</p><p>错误显示：</p><pre><code class="language-text">The selected directory is not a valid home for Go SDK
</code></pre><p>通过 go env 查看后发现相关配置无问题，环境变量也无问题。</p><p>最后找的解决方案：
1、go version 查看自己当前版本<br/>
<!-- -->2、编辑 {GOROOT}/src/runtime/internal/sys/zversion.go 文件，写入以下变量</p><pre><code class="language-go">const TheVersion = `go1.17.4`
</code></pre><p>3、重启 goland，然后点击 setroot 即可。  </p><br/><p>:::info 👇👇👇
<strong>本文作者:</strong> Czasg<br/>
<strong>版权声明:</strong> 转载请注明出处哦~👮‍
:::</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Jmeter及性能测试]]></title>
            <link>https://czasg.github.io/docusaurus/blog/2022/2/2/Jmeter及性能测试</link>
            <guid>Jmeter及性能测试</guid>
            <pubDate>Wed, 02 Feb 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[记录 jmeter 工具的使用，以及在性能测试过程中学习到的一些知识点。]]></description>
            <content:encoded><![CDATA[<p>记录 jmeter 工具的使用，以及在性能测试过程中学习到的一些知识点。</p><h2>性能指标</h2><ul><li>TPS（Transactions Per Second）：每秒事务数，吞吐率</li><li>QPS（Queries Per Second）：每秒查询数</li><li>RT（Response Time）：响应时间，服务延迟</li></ul><p>性能问题，归根结底还是资源问题。常见的瓶颈点：<br/>
<!-- -->1、网络IO<br/>
<!-- -->2、存储IO<br/>
<!-- -->3、CPU、内存<br/>
<!-- -->4、应用  </p><h2>jmeter 结果解读</h2><p>并发线程、响应时间、TPS之间的关联：</p><pre><code class="language-text">TPS = (1s/响应时间) * 并发线程
</code></pre><p>:::note
假设有4个线程，每个线程每秒发起4个请求并响应，此时并发是16而非4
:::</p><pre><code class="language-text" metastring="title=&quot;1个线程&quot;" title="&quot;1个线程&quot;">summary +   5922 in 00:00:30 =  197.4/s Avg:     4 Min:     0 Max:    26 Err:     0 (0.00%) Active: 1 Started: 1 Finished: 0
summary =  35463 in 00:03:05 =  192.0/s Avg:     5 Min:     0 Max:   147 Err:     0 (0.00%)
summary +   5922 in 00:00:30 =  197.5/s Avg:     4 Min:     0 Max:    24 Err:     0 (0.00%) Active: 1 Started: 1 Finished: 0
summary =  41385 in 00:03:35 =  192.8/s Avg:     5 Min:     0 Max:   147 Err:     0 (0.00%)
summary +   5808 in 00:00:30 =  193.6/s Avg:     5 Min:     0 Max:    25 Err:     0 (0.00%) Active: 1 Started: 1 Finished: 0
summary =  47193 in 00:04:05 =  192.9/s Avg:     5 Min:     0 Max:   147 Err:     0 (0.00%)
</code></pre><p>(1000ms/5ms)*1=200TPS</p><pre><code class="language-text" metastring="title=&quot;10个线程&quot;" title="&quot;10个线程&quot;">summary +  11742 in 00:00:30 =  391.3/s Avg:    25 Min:     0 Max:   335 Err:     0 (0.00%) Active: 10 Started: 10 Finished: 0
summary =  55761 in 00:02:24 =  386.6/s Avg:    25 Min:     0 Max:   346 Err:     0 (0.00%)
summary +  11924 in 00:00:30 =  397.5/s Avg:    25 Min:     0 Max:    80 Err:     0 (0.00%) Active: 10 Started: 10 Finished: 0
summary =  67685 in 00:02:54 =  388.5/s Avg:    25 Min:     0 Max:   346 Err:     0 (0.00%)
summary +  11884 in 00:00:30 =  396.2/s Avg:    25 Min:     0 Max:   240 Err:     0 (0.00%) Active: 10 Started: 10 Finished: 0
summary =  79569 in 00:03:24 =  389.6/s Avg:    25 Min:     0 Max:   346 Err:     0 (0.00%)
</code></pre><p>(1000ms/25ms)*10=400TPS</p><h2>分布式压力测试</h2><pre><code class="language-shell" metastring="script title=&quot;启动指令&quot;" title="&quot;启动指令&quot;">/jmeter/bin/jmeter -n -t tmpl.jmx -R 1.1.1.1:8000,1.1.1.2:8000
</code></pre><br/><p>:::info 👇👇👇
<strong>本文作者:</strong> Czasg<br/>
<strong>版权声明:</strong> 转载请注明出处哦~👮‍
:::</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[常用 sql 操作]]></title>
            <link>https://czasg.github.io/docusaurus/blog/2022/1/20/常用 sql 操作</link>
            <guid>常用 sql 操作</guid>
            <pubDate>Thu, 20 Jan 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[整理下 sql 常见的操作。]]></description>
            <content:encoded><![CDATA[<p>整理下 sql 常见的操作。</p><h2>mysql</h2><h2>postgres</h2><h3>建表</h3><pre><code class="language-sql" metastring="title=&quot;创建普通表&quot;" title="&quot;创建普通表&quot;">CREATE TABLE IF NOT EXISTS my_table (
    k  text,
    v  text
)
</code></pre><pre><code class="language-sql" metastring="title=&quot;创建临时表&quot;" title="&quot;创建临时表&quot;">CREATE TEMPORARY TABLE IF NOT EXISTS my_table (
    k  text,
    v  text
) ON COMMIT DROP;
</code></pre><pre><code class="language-sql" metastring="title=&quot;删除表&quot;" title="&quot;删除表&quot;">DROP TABLE IF EXISTS my_table; -- 普通删除
DROP TABLE IF EXISTS my_table CASCADE; -- 级联删除
</code></pre><h3>索引</h3><pre><code class="language-sql">CREATE INDEX IF NOT EXISTS my_table_hash_index USING HASH(k);
DROP INDEX IF EXISTS my_table_hash_index;
</code></pre><h3>插入</h3><pre><code class="language-sql">INSERT INTO my_table (k, v) VALUES (&#x27;k&#x27;, &#x27;v&#x27;); -- 插入单条
INSERT INTO my_table (SELECT * FROM same_table); -- 相同结构表之间的批量插入
INSERT INTO my_table (k, v) (SELECT k, v FROM other_table); -- 不同结构表之间的批量插入
</code></pre><h3>更新</h3><pre><code class="language-sql">UPDATE my_table SET v = &#x27;new_v&#x27; WHERE k = &#x27;new_k&#x27;; -- 更新一次
UPDATE my_table AS o SET v = new_table.v FROM (SELECT * FROM other_table) as new_table WHERE o.k = new_table.k; -- 批量更新
</code></pre>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[redis 整理]]></title>
            <link>https://czasg.github.io/docusaurus/blog/2022/1/18/redis 整理</link>
            <guid>redis 整理</guid>
            <pubDate>Tue, 18 Jan 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[整理下 redis 常见知识点。]]></description>
            <content:encoded><![CDATA[<p>整理下 redis 常见知识点。</p><p>:::note redis 单线程理解
在 6.0 版本之前，redis 内部的网络IO和键值对的读写是在同一个线程中完成的。<br/>
<!-- -->但类似数据持久化、主从同步等，都是多线程完成的。所以本质上，redis 并不是一个绝对的单线程服务。
而官方之所以这样描述，也只是因为他的核心逻辑都是单线程实现的，然后还能提供这么高的并发，整体听上去就很牛了。</p><p>在 6.0 版本之后，redis 在网络IO部分引入了多线程，而键值对的读写则还是由单线程完成。  </p><p>:::</p><h2>常见数据类型</h2><ul><li>string</li><li>hash</li><li>list</li><li>set</li><li>zset</li><li>bitmap</li><li>hyperloglog</li><li>geo</li></ul><h2></h2>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[nginx 配置说明]]></title>
            <link>https://czasg.github.io/docusaurus/blog/2022/1/12/nginx配置说明</link>
            <guid>nginx 配置说明</guid>
            <pubDate>Wed, 12 Jan 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[记录一下 nginx 常见配置说明和部署模板（docker、k8s）。]]></description>
            <content:encoded><![CDATA[<p>记录一下 nginx 常见配置说明和部署模板（docker、k8s）。</p><p>nginx 是一个高性能的 web 服务器，同时也能提供负载均衡和反向代理服务。</p><h2>nginx 常用指令</h2><ul><li>-c：用于指定一个配置文件</li><li>-t：用于测试配置是否可用</li><li>-s：用于发送信号，包括：stop, quit, reopen, reload。eg：<code>nginx -s reload</code></li></ul><pre><code class="language-shell" metastring="script title=&quot;指定并测试配置文件是否正确&quot;" title="&quot;指定并测试配置文件是否正确&quot;">nginx -t -c ./nginx.conf
</code></pre><h2>nginx 核心模块</h2><p>nginx 的核心模块主要有三个：</p><ul><li>主模块：管理 nginx 基本功能的模块</li><li>事件模块：管理 nginx 处理连接请求的模块</li><li>HTTP 模块：管理 nginx 处理 http 请求的模块</li></ul><h3>主模块</h3><pre><code class="language-text">user  nginx;  # 用户
pid  /var/run/nginx.pid;  # 进程ID
worker_processes  auto;  # 工作进程，可以指定具体数字
error_log  /var/log/nginx/error.log notice;  # 指定日志和错误级别，包含：debug、info、notice、warn、error、crit

worker_cpu_affinity  none;  # 用于绑定 worker 进程与 cpu
</code></pre><h3>事件模块</h3><pre><code class="language-text">events {
    worker_connections  1024;  # 每个工作进程最大链接数。乘以 worker_processes 就是该 nginx 服务的最大连接数
}
</code></pre><h3>HTTP 模块</h3><h4>location 路由匹配规则及顺序</h4><ul><li><code>=</code>: 精确匹配</li><li><code>^~</code>: 优先前缀匹配</li><li><code>~</code>: 正则匹配，区分大小写</li><li><code>~*</code>: 正则匹配，不区分大小写</li><li><code>!~</code>: 正则匹配，区分大小写</li><li><code>!~*</code>: 正则匹配，不区分大小写</li><li><code>/route</code>: 普通前缀匹配</li><li><code>/</code>: 通用匹配</li></ul><blockquote><p>精确匹配 &gt; 优先前缀匹配 &gt; 正则匹配 &gt; 普通前缀匹配 &gt; 通用匹配</p></blockquote><pre><code class="language-text">http {
    server {
        # 优先匹配依次往下
        location = /route { return 200; }
        location ^~ /route { return 201; }
        location ~ ^/route { return 202; }
        location /route { return 203; }
        location / { return 204; }
    }
}
</code></pre><h4>upstream 负载均衡策略</h4><ul><li>轮询：在每个服务之间轮询请求</li><li>weight：按指定权重比例在服务之间请求，默认 weight 为 1</li><li>ip_hash：按照请求 IP 计算 Hash，保证每次请求都访问同一个服务</li><li>fair：按照后端的响应时间来分配（三方插件实现）</li></ul><pre><code class="language-text">http {
    # 负载均衡
    upstream serverName {
        # ip_hash;  # 指定 ip_hash 负载均衡策略
        server 10.251.10.10:8080 weight=2;  # 指定权重比例
        server 10.251.10.10:8081 down;  # down 表示服务下线
        server 10.251.10.10:8082;
        server 10.251.10.10:8083 backup;  # backup 表示备用，当其他机器 down 或者压力比较大时，流量会走到此服务
        # fair;  # 指定 fair 负载均衡策略
    }

    server {
        listen  80;  # 监听端口
        server_name  _;  # 不启用域名检测

        location / {
            proxy_pass  http://serverName;  # 指定 upstream 名字即可
        }
    }
}
</code></pre><h4>http 客户端与服务端参数配置</h4><pre><code class="language-text">http {
    server {
        client_body_timeout  60s;  # 定义读取客户端请求体的超时
        client_body_buffer_size  8k;  # 设置读取客户端请求体的缓冲区大小（超过则存储到临时文件中）
        client_header_timeout  60s;  # 定义读取客户端请求头的超时
        client_header_buffer_size  1k;  # 设置读取客户端请求头的缓冲区大小
        client_max_body_size  0;  # 数据最大传输限制
        proxy_request_buffering  off;  # 默认开启，作用是缓冲请求。关闭后请求会立即转发到后端服务
        proxy_buffering  off;  # 对代理服务器的响应内容缓冲
        proxy_buffer_size  4k;  # 从代理服务器获取部分响应后进行缓冲
        proxy_buffers  8 4k;  # 从被代理的后端服务器取得的响应内容，会缓冲到这里
        proxy_connect_timeout  60s;  # 与后端服务建立连接的超时时间
        proxy_send_timeout  60s;  # 向后端传输请求的超时时间
        proxy_read_timeout  60s;  # 从后端读取响应的超时时间
        proxy_set_header  Host $proxy_host;

        proxy_set_header  Host $proxy_host;

        location / {
            proxy_set_header  Auth &quot;auth-key&quot;;
            proxy_pass  http://serverName;
        }
    }
}
</code></pre><pre><code class="language-text">http {
    server {
        location /index {
            index  index.html;  # 首页，即未指定后续路径时，匹配首页
        }
        location /try_files {
            root  /static
            try_files  $uri index.html;  # 依次尝试。/try_files/file -&gt; /try_files/static/file
        }
        location /alias/ {
            alias  /a/new/route/;  # 请求路径 /alias/files 等效于 /a/new/route/files，会替换掉匹配路由
        }
        location /root {
            root  /a/new/route/;  # 请求路径 /root/files 等效于 /a/new/route/root/files，会保留匹配路由
            # proxy_pass  http://serverName/;  # /root/index.html -&gt; http://serverName/index.html
            # proxy_pass  http://serverName;  # /root/index.html -&gt; http://serverName/root/index.html
        }
        location /rewrite {
            rewrite  ^/rewrite/permanent/(.*) http://serverName/$1 permanent;  # 301 永久重定向
            rewrite  ^/rewrite/redirect/(.*) http://serverName/$1 redirect;  # 302 临时重定向
            rewrite  ^/rewrite/last/(.*) http://serverName/$1 last;  # 实现重定向
            rewrite  ^/rewrite/break/(.*) http://serverName/$1 break;  # 实现重定向
        }
    }
}
</code></pre><h4>mirror</h4><pre><code class="language-text">http {
    server {
        location /mirror {
            mirror  /internal;  # mirror 实现流量拷贝
            proxy_pass  http://serverName;
        }

        location /internal {
            internal;  # 表示仅被内部请求发现
            proxy_pass  http://serverName;  # 指定 upstream 名字即可
        }
    }
}
</code></pre><br/><p>:::info 👇👇👇
<strong>本文作者:</strong> Czasg<br/>
<strong>版权声明:</strong> 转载请注明出处哦~👮‍<br/>
<!-- -->:::</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[字符编码]]></title>
            <link>https://czasg.github.io/docusaurus/blog/2021/12/15/字符编码</link>
            <guid>字符编码</guid>
            <pubDate>Wed, 15 Dec 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[字符串是使用的最多的数据类型之一。]]></description>
            <content:encoded><![CDATA[<p>字符串是使用的最多的数据类型之一。<br/>
<!-- -->如果说在使用过程中会遇到什么问题，那可以说，大部分都是编码方面的问题了。</p><h2>ascii 编码</h2><blockquote><p>字符编码的本质，是数字到字符串的映射</p></blockquote><p>最早的编码是 ascii 编码，它是一个包含 127 个字符的字符集，可以编码字母和特殊字符。</p><p>:::note 比特与字节
由于计算机底层只能够处理数字，如果要处理类似文本图片等数据，就需要先将这些数据转化为数字才能够继续处理。<br/>
<!-- -->最早计算机在设计时采用 8 个比特（bit）作为一个字节（byte），所以一个字节能表示的最大数字就是 255，二进制表示 <code>1111 1111</code></p><p>如果需要表示更大的数，就需要更多的字节
:::</p><h2>unicode 编码</h2><p>随着计算机的发展，单一的 ascii 编码已经无法满足多元的文化需求。<br/>
<!-- -->计算机需要支持更多的编码集，例如：中国制定有 gb2312，其他国家也有类似的编码集。</p><p>虽然每个国家都实现了特定的编码，但是当一个文本中混合了多个国家的语言时，就不可避免的出现局部乱码。</p><p>为了解决这个问题，业界决定使用统一的 unicode 编码。<br/>
<!-- -->即将所有国家的编码收录到一个字符集中。</p><h2>utf-8 编码</h2><p>虽然 unicode 可以解决乱码问题，但是会出现一个这样的问题：<br/>
<!-- -->中英混合时，一个中文可能需要占据两个字节，这个时候为了正确编码，原本只需要占据一个字节的英文，不得不占据两个字节。<br/>
<!-- -->从而造成了资源浪费。</p><p>为了解决这个缺陷，基于 unicode 编码又推出了可变长编码 utf-8</p><p>即 utf-8 会根据实际类型选择最佳的字节占位，从而节省空间。</p><h2>计算机通用编码方式</h2><p>搞清楚了 ascii、unicode、utf-8 编码，我们梳理下计算机通用的编码方式：<br/>
<!-- -->1、在计算机内存中，统一使用 unicode 编码<br/>
<!-- -->2、当需要保存到硬盘或者传输的时候，转化为 utf-8 编码   </p><p>以我们的 txt 文本为例：<br/>
<!-- -->1、打开文本：数据以 unicode 编码，以便展示内容。<br/>
<!-- -->2、保存文本：数据以 utf-8 编码，以便节约空间。</p><br/><p>:::info 👇👇👇
<strong>本文作者:</strong> Czasg<br/>
<strong>版权声明:</strong> 转载请注明出处哦~👮‍<br/>
<!-- -->:::</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[基于 gRPC 实现负载均衡]]></title>
            <link>https://czasg.github.io/docusaurus/blog/2021/12/13/gRPC负载均衡</link>
            <guid>基于 gRPC 实现负载均衡</guid>
            <pubDate>Mon, 13 Dec 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[本文主要介绍在 k8s 环境下 gRPC 服务在实现负载均衡时遇到的问题和解决思路。]]></description>
            <content:encoded><![CDATA[<p>本文主要介绍在 k8s 环境下 gRPC 服务在实现负载均衡时遇到的问题和解决思路。</p><h2>概述</h2><p>我们的 gRPC 应用最初使用 <code>DaemonSet</code> 类型的资源对象部署在 k8s 上。通过污点和容忍配置，使得单台 Node 节点不在部署其他 Pod 应用。
而该 gRPC 应用，则通过 <code>NodePort Service</code> 的方式对外暴露服务。</p><p>在这种场景下直接对外暴露固定 IP 提供服务，业务流量全部打到单台宿主机上，所以也不存在负载均衡的说法。</p><p>随着业务压力逐渐增大，单点提供的能力已逐渐达到极限，我们采用水平拓展的方式，部署了多台单节点服务。也算暂时抗住了压力。但随后的暴露的问题，也让我们被迫选择了重构。</p><p>:::note 为什么选择重构
业务持续拓展，引入多节点的问题也逐渐暴露出来，当前服务架构下，多节点之间的数据一致性完全不能保证，人工运维简直不要太恶心，无奈只能重构。这里我们不针对此展开。<br/>
<!-- -->:::</p><p>服务改造升级完毕后，完全兼容历史 gRPC 接口，在 k8s 的配置上也有部分改动，以前的 <code>DaemontSet</code> 资源变更为 <code>Deployment</code> 资源，而 <code>NodePort Service</code> 资源则变更为 <code>ClusterIP Service</code> 资源。
项目正式进入到了提测阶段。</p><p>功能上基本没有太大的问题，毕竟引用了相同的 gRPC 接口文件。</p><p>问题主要出现在了负载均衡上，在多副本的场景下，发生了严重的流量倾斜，具体表现就是某个副本的压力非常高，而其他副本的压力很小，进而导致服务整体异常。</p><p>:::tip 简单分析
gRPC 是基于 HTTP2.0 实现的长连接，且默认没有超时，这种长连接能够大量减少 TCP 连接管理所带来的开销，但也破坏了标准的连接级的负载均衡。因为连接已经建立且不断开，也无法再进一步负载均衡了。  </p><p>那么再回到上述场景，显然就是客户端与某个具体的服务建立了长连接，而连接又不会断开，从而导致了持续的流量倾斜问题。
:::</p><p>选择有效的 gRPC 负载均衡方案，是解决我们当前问题的核心。</p><p>具体解决的方法有多种，我们主要将其分为：  </p><ul><li>用户侧的负载均衡</li><li>服务侧的负载均衡</li></ul><h2>gRPC 负载均衡 - 用户侧</h2><p>用户侧的 gRPC 负载均衡，是通过 DNS，使用户解析出全部的 gRPC 服务地址，然后用户自己实现负载策略。
最简单的策略就是与每个服务建立 gRPC 连接，然后轮询访问，实现 rr 负载。</p><p><img src="client-load-balancer.png"/></p><p>该方案实施起来比较容易，但对于用户侧有一定的要求。如：</p><ul><li>安全方面，要考虑用户的可靠性。</li><li>更新策略，解析 DNS 虽有现成的方案，但是常规方案一般无法探知到后续新创建的服务，所以需要设计更新策略。</li></ul><h2>gRPC 负载均衡 - 服务侧</h2><p>服务侧的 gRPC 负载均衡，需要引入一个负载均衡代理，我们称之为 <code>Load Balancer</code>，
用户向 LB 发起 RPC 请求，然后由该 LB 将 RPC 分配到一个可用的后端服务器上，
由该服务器提供 gRPC 服务，并将负载情况报告给 LB，进一步补全 LB 的负载信息。
<img src="server-load-balancer.png"/></p><p>在该方案中，负载均衡由 LB 统一管理，有一定的实施难度。<br/>
<!-- -->除非能找到高 star 的开源项目，不然开发与运维就是一笔不小的投入。</p><h2>方案选择</h2><p>考虑到实施难度，我们选择了用户侧的负载均衡方式。</p><p>首先要解决 DNS 的解析与负载，这一块，官方已经封装了 gRPC SDK，故用户可以通过升级 SDK 实现该功能。问题就在如何检测更新这一块了。</p><p>解决的方案也有两种：<br/>
<!-- -->1、服务端实现：MaxConnectionAge<br/>
<!-- -->2、客户端实现：KubeResolver   </p><p>:::info MaxConnectionAge
MaxConnectionAge 是 gRPC 服务端的参数，用于指定长连接最大保持时间。<br/>
<!-- -->配置该参数会使得长连接变成“短”连接，故性能会有一定的降低。</p><p>该方案的原理是，通过定期释放连接，使得客户端重新解析 DNS 获取最新的服务地址。
:::</p><p>:::info KubeResolver
该方案的原理是通过监听 k8s 的 api 资源状态，实时获取 gRPC 服务资源信息，从而实现检测更新。
:::</p><p>综合考虑后，最终选择了 MaxConnectionAge 方案，因为此方案仅仅通过适配参数就可以完成预期功能，虽然略显僵硬，但实际上效果还不错。</p><br/><p>:::info 👇👇👇
<strong>本文作者:</strong> Czasg<br/>
<strong>版权声明:</strong> 转载请注明出处哦~👮‍<br/>
<!-- -->:::</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[关于副业的一些思考]]></title>
            <link>https://czasg.github.io/docusaurus/blog/2021/12/10/关于副业的一些思考</link>
            <guid>关于副业的一些思考</guid>
            <pubDate>Fri, 10 Dec 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[所谓副业，本质上就是打多份工...]]></description>
            <content:encoded><![CDATA[<p>所谓副业，本质上就是打多份工...</p><p>一定要和打工区别开来的话，可能就是我们如今所说的副业，更多的带上了对人生规划的一些思考。</p><h2>知道想做什么</h2><p>知道自己想做什么，永远是第一步。</p><p>我们常常听到别人高谈自己的&quot;规划&quot;，其实&quot;规划&quot;并不神秘。<br/>
<!-- -->你可以把他理解为一些简单的想法，或者说是对未来的一些想法，他们可以是想做的事，也可以是想去的地方...   </p><p>但事实是很多人不知道想做什么。<br/>
<!-- -->我们的第一份工作，往往和我们第一学历专业挂钩。<br/>
<!-- -->而大学毕业后，毕业生真正知道自己应该干什么的，其实寥寥无几。甚至可能工作两三年后才突然醒悟应该转投其他行业。</p><p>比如我本人是工程管理学专业，但我毕业后就投入到了互联网行业，因为我知道我不喜欢进工厂，相反我很喜欢计算机编程。<br/>
<!-- -->而我的大部分同学，毕业两三年后也陆陆续续的转行...</p><p>所以，我觉得很重要的一点，就是要想清楚自己现阶段到底需要做什么。<br/>
<!-- -->你需要取尝试做一个决定，这也许这不是一个长期的决定，但是它应该是现阶段你能够稳定投入精力的一个决定。</p><p>这个时候，也不需要考虑什么主业副业，能做好一件就已经很了不起了。</p><h2>为什么需要副业</h2><p>那为什么现在又有这么多人选择副业呢？</p><p>以我自己的情况来说，毫无疑问，是典型的属于需要依靠打工来维持生计的群体。个人睡后收入纯靠银行利息，工作的本质是为了混口饭吃。<br/>
<!-- -->当然我没有副业，因为互联网并不算特别轻松，我个人时间也并不是很充裕，很难花时间去思考打第二份工作。
况且互联网收入相对来说是可以的。   </p><p>然而，这一切在我买房之后就改变了...<br/>
<!-- -->试想，当你的一半甚至一大半收入，全部用于还贷了，还得还三十年，一股有形的压力瞬间压得人喘不过气来。  </p><p>所以并不是我很闲，闲的要去找一份副业来充实自己，而是我很需要第二份收入来充实自己...<br/>
<!-- -->现在社会大环境又不好，工资过万，你可以打败全国一半以上的打工群体，但在一二线城市的房价物价面前，就是个屁。</p><p>所以，我想到的能坚持发展副业的人群：<br/>
<strong>1、</strong>入不敷出。<br/>
<strong>2、</strong>闲不下来。<br/>
<strong>3、</strong>个人爱好。    </p><p>但整体来看，时间和精力才是最终落地执行的决定因素。<br/>
<!-- -->对于一个不爱惜自己身体健康的人，建议是直接去国外买血袋。</p><h2>认知自己的工作阶段</h2><p>当你有发展副业的想法时，我还是建议先梳理下你自己当前的工作情况，对于一份稳定的工作，应该大致朝着这个阶段方向发展：  </p><ul><li><strong>积累阶段</strong></li></ul><p>一般指一些刚入行的同学，在这个阶段他们需要去积累一些工作经验。</p><p>处于这个阶段时，会有一些比较明显的特点。<br/>
<!-- -->比如你的简历上面，可能需要编造大量技能和项目经验，以便通过 HR 的筛选。
一旦面试被人追着问细节时，就会暴露。</p><ul><li><strong>瓶颈阶段</strong></li></ul><p>一般指在某个领域有足够的经验。</p><p>处于这个阶段，你可能不在需要投递简历就能很轻松的找到一份工作。
如果工作不开心，你也很自信可以很快找到另一份工作，虽然找的不一定更好，但不用担心失业问题。</p><ul><li><strong>溢出阶段</strong></li></ul><p>一般指在某个领域有足够经验，在公司也处于中高层。</p><p>你可以很轻松的获取工作之外的报酬，比如公司分红等。</p><h2>关于副业的思考 - 给自己</h2><p>首先，不能盲目跟风，因为有很多发展副业的人都是事业编制，他们相对来说个人时间比较充裕。<br/>
<!-- -->还有一部分牛人达到了工作的 <strong>瓶颈阶段</strong> 甚至是 <strong>溢出阶段</strong>，他们有能力去执行副业计划。</p><p>互联网，是一个新兴技术频繁更替的行业。而我也通过不断的学习，取得了一定的汇报。</p><br/><p>:::info 👇👇👇
<strong>本文作者:</strong> Czasg<br/>
<strong>版权声明:</strong> 转载请注明出处哦~👮‍
:::</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Github 搭建 Docusaurus 站点]]></title>
            <link>https://czasg.github.io/docusaurus/blog/2021/12/3/Github搭建Docusaurus站点</link>
            <guid>Github 搭建 Docusaurus 站点</guid>
            <pubDate>Fri, 03 Dec 2021 00:00:00 GMT</pubDate>
            <description><![CDATA[本文章记录基于 Docusaurus 搭建静态站点，并通过 Github-Actions 实现自动部署。]]></description>
            <content:encoded><![CDATA[<p>本文章记录基于 Docusaurus 搭建静态站点，并通过 Github-Actions 实现自动部署。</p><h2>1、新建 Github 仓库</h2><p>首先，登录<a href="https://github.com/new">Github仓库创建页面</a>，我们创建一个全新的空白仓库，项目名命名为 <code>testDocusaurus</code>。</p><p>然后通过 <code>git</code> 将仓库拉取到本地，至此，我们拥有了一个全新的空白仓库 <code>testDocusaurus</code>。  </p><p><img src="gitindex.png"/></p><h2>2、初始化 Docusaurus 项目</h2><blockquote><p><a href="https://docusaurus.io/zh-CN/docs/installation">Docusaurus项目初始化细节请参考官方文档</a></p></blockquote><p>进入到仓库 <code>testDocusaurus</code> 所在的空白目录，并在此目录打开终端界面。</p><p>为了更好的完成接下来的步骤，你可能需要预先安装<strong>nodejs</strong>。在此，假设你已经准备完毕。<br/>
<!-- -->那我们接下来通过以下指令初始化一个 <code>Docusaurus</code> 项目。</p><pre><code class="language-shell" metastring="script">&gt;&gt;&gt; npx create-docusaurus@latest website classic
...
...
Successfully created &quot;website&quot;.
Inside that directory, you can run several commands:

  npm start
    Starts the development server.

  npm run build
    Bundles your website into static files for production.

  npm run serve
    Serves the built website locally.

  npm deploy
    Publishes the website to GitHub pages.

We recommend that you begin by typing:

  cd website
  npm start

Happy building awesome websites!
</code></pre><p>该指令运行完后，会输出一些简单的运行指令，而且我们应该可以看到一个 <code>website</code> 的目录，我们先将里面的内容剪贴出来，放到我们空白仓库目录下面。</p><p>此时，我们按照提示，运行 <code>npm start</code> 指令，我们就可以运行此项目。</p><p>通常启动端口为3000，则默认路径为：http://localhost:3000/  </p><p><img src="websiteindex.png"/></p><h2>3、搭建 Github Actions</h2><blockquote><p>Github Actions部署细节参考<a href="https://docusaurus.io/zh-CN/docs/deployment#deploying-to-github-pages">官方文档</a></p></blockquote><p>接入 <code>Github Actions</code> 需要创建一对新的 <strong>SSH Key</strong>，并将公钥和密钥均配置到 Github，我们来具体看下操作。</p><p>首先创建密钥，我们可以指定一个新的目录，然后得到公钥（id_rsa.pub）和私钥（id_rsa）</p><pre><code class="language-shell" metastring="script">&gt;&gt;&gt; ssh-keygen -t rsa -C &quot;email&quot;
...
...
The key&#x27;s randomart image is:
+---[RSA 3072]----+
| .=oo*=o=o.      |
| o+.=o==.o       |
|  .O.O=+o        |
|  ..=o@.oo       |
| . o +.+S+..     |
|  . + . E.o      |
|   o . .         |
|  .              |
|                 |
+----[SHA256]-----+
</code></pre><p>我们打开仓库的 <code>deploy keys</code>，选择新增，将 <code>id_rsa.pub</code> 中的内容复制进去，并选中 <code>Allow write access</code> 框，表示赋予部署写权限。
<img src="deploykey.png"/></p><p>此时部署公钥已经完成，我们再将私钥也配置上。打开同级配置下的 Secret，选择新增密钥，
我们将私钥内容复制到 <code>Value</code> 中，而 <code>Name</code> 填写 <code>GH_PAGES_DEPLOY</code> 即可。</p><p>最后，我们创建 <code>Github Actions</code>，将模板复制进去，则整个流水线就已经配置好了。复制时，将对应的基础配置改下即可，如下：</p><pre><code class="language-shell" metastring="script">git config --global user.email &quot;email&quot;
git config --global user.name &quot;name&quot;
</code></pre><p>这里的 <code>email</code> 需要是 github 配置的 email，而 <code>name</code> 则是 github 用户名。</p><h2>4、更新仓库，尝试自动部署</h2><p>确保 Github Pages 已经初始化好，那么我们往仓库推送修改时，就可以触发自动部署了。</p><br/><p>:::info 👇👇👇
<strong>本文作者:</strong> Czasg<br/>
<strong>版权声明:</strong> 转载请注明出处哦~👮‍<br/>
<!-- -->:::</p>]]></content:encoded>
        </item>
    </channel>
</rss>