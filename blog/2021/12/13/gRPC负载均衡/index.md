---
title: 基于 gRPC 实现负载均衡
authors: [czasg]
tags: [k8s, gRPC, 负载均衡]
---

<!-- 参考自 https://www.lixueduan.com/post/grpc/13-loadbalance-on-k8s/ -->

本文主要介绍在 k8s 环境下 gRPC 服务在实现负载均衡时遇到的问题和解决思路。

<!--truncate-->

## 概述
我们的 gRPC 服务最初使用 `DaemonSet` 部署在 k8s 上，通过节点亲和属性 `nodeAffinity`，使得单台宿主机仅运行这一个 `Pod`，然后通过 `NodePort Service` 的方式对外暴露服务。

在这种场景下直接对外暴露 IP 提供服务，业务流量全部打到单台宿主机上，所以也不存在负载均衡的说法。

随着业务压力逐渐增大，单点提供的能力已逐渐达到极限，我们采用水平拓展的方式，部署了多台单节点服务。也算暂时抗住了压力。但随后的暴露的问题，也让我们被迫选选择了重构。

:::note 为什么选择重构
业务持续拓展，问题也逐渐暴露出来，当前服务架构下，多节点之间的数据一致性完全不能保证，人工运维简直不要太恶心，无奈只能重构。这里我们不针对此展开。  
:::

服务改造升级完毕后，完全兼容历史 gRPC 接口，在 k8s 的配置上也有部分改动，以前的 `DaemontSet` 类型变更为 `Deployment` 类型，而 `NodePort Service` 类型则变更为 `ClusterIP Service` 类型。
项目正式进入到了提测阶段。

功能上基本没有太大的问题，毕竟引用了相同的 gRPC 标准。

问题主要暴露在了负载均衡上，在多副本的场景下，发生了严重的流量倾斜，具体表现就是某个副本的压力非常高，而其他副本的压力很小，进而导致服务整体异常。

:::tip 简单分析
gRPC 是基于 HTTP2.0 实现的长连接，且默认没有超时，这种长连接能够大量减少 TCP 连接管理所带来的开销，但也破坏了标准的连接级的负载均衡。因为连接已经建立且不断开，也无法再进一步负载均衡了。  

那么再回到上述场景，显然就是客户端与某个具体的服务建立了长连接，而连接又不会断开，从而导致了持续的流量倾斜问题。
:::

如何选择有效的 gRPC 负载均衡方案，具体解决的方法有多种，我们主要将其分为：  
* 用户侧的负载均衡
* 服务侧的负载均衡

## gRPC 负载均衡 - 用户侧


### Headless Service
k8s 的 `Service` 是一个
`ClusterIP Service`

### KubeResolver

## gRPC 负载均衡 - 服务侧

### 长连接转短连接

### 中间件


<br/>

:::info 👇👇👇
**本文作者:** Czasg     
**版权声明:** 转载请注明出处哦~👮‍    
:::
